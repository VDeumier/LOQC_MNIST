{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceval Quest\n",
    "#### Author: *Valentin Deumier*\n",
    "\n",
    "Our goal is to start by creating a 'classical' neural network and train it on the famous MNIST handwritten digits dataset, and then try to upgrade it by using Linear Optical Quantum Computing, in hope to increase the accuracy of the model and lower the duration of the calculations.\n",
    "\n",
    "### <u>2: A hybrid model</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 09:15:35.352424: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-14 09:15:35.395081: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-14 09:15:36.085861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/deumier/Documents/LOQC_MNIST/.venv/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"12\"\n",
    "print(np.__version__)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import perceval as pcvl\n",
    "import perceval.components as comp\n",
    "from perceval.rendering.circuit import SymbSkin, PhysSkin\n",
    "from perceval import Circuit\n",
    "from perceval import catalog\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 28, 28, 1) (6000, 10) (600, 28, 28, 1) (600, 10)\n",
      "(6000, 7, 7, 1) (6000, 10) (600, 7, 7, 1) (600, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 09:15:40.513873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31044 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:d5:00.0, compute capability: 7.0\n",
      "2025-01-14 09:15:40.831794: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907\n"
     ]
    }
   ],
   "source": [
    "# Data into numpy arrays\n",
    "def load_data(filename):\n",
    "\n",
    "    data = pd.read_csv(filename)\n",
    "    X = np.array(data['image'].str.split(',', expand=True).values)\n",
    "\n",
    "    # Remove the [ ] from the image data (fastest method I found)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            X[i, j] = X[i, j].replace('[', '').replace(']', '')\n",
    "    X = X.astype(float)\n",
    "\n",
    "    y = data['label'].values\n",
    "\n",
    "    X = X.reshape(-1, IMG_SIZE, IMG_SIZE, 1)/255.0      # Reshape and normalize\n",
    "    y = to_categorical(y, NUM_CLASSES)\n",
    "    return X, y\n",
    "\n",
    "# Get the absolute path to the data folder\n",
    "script_dir = os.getcwd()\n",
    "data_dir = os.path.join(script_dir, 'data')\n",
    "\n",
    "# Load the data\n",
    "train_file = os.path.join(data_dir, 'train.csv')\n",
    "X_train, y_train = load_data(train_file)\n",
    "val_file = os.path.join(data_dir, 'val.csv')\n",
    "X_val, y_val = load_data(val_file)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)\n",
    "\n",
    "# Divide the image resolution by 4 using max pooling and avg pooling\n",
    "X_train = np.array(tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(X_train))/255.0\n",
    "X_val = np.array(tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(X_val))/255.0\n",
    "\n",
    "X_train = np.array(tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(X_train))\n",
    "X_val = np.array(tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(X_val))\n",
    "\n",
    "# This step is necessary as the number of modes needed for the circuit is IMG_SIZE, \n",
    "# and I found that seven modes is a maximum that I can do before the calculation takes too long\n",
    "# It could be improved with better computing ressources\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to encode the image data into quantum data while preserving the 2-dimensional structure of the image. \\\n",
    "\\\n",
    "Like in the CNN model, we want neighbours pixels to remain close to each other in the quantum representation so that we can perform \"local\" transformation (the equivalent of convoluting the image with a kernel), so the representation has to be continuous along both axis.\\\n",
    "This means that we can't flatten the data, so we can't use basis, angle or amplitude embedding.\\\n",
    "\\\n",
    "An idea could be to encode the image in a matrix representation of a unitary transformation (that could also be parametrized, and have its parameters be optimized).\\\n",
    "\\\n",
    "Being inspired by the solution of Schrodinger's equation for a time-independant Hamiltonian, we are going to represent the image $\\mathbf{x}$ as the resulting evolution operator :\n",
    "\n",
    "$$ U_t(\\mathbf{x}) = \\exp(-iH_{\\mathbf{x}}t) $$\n",
    "\n",
    "Where $H_{\\mathbf{x}}$ is the symetric part of our image matrix (so that $U_t(\\mathbf{x})$ is unitary):\n",
    "\n",
    "$$ H_{\\mathbf{x}} = \\frac{\\mathbf{x} + \\mathbf{x}^T}{2} $$\n",
    "\n",
    "with $t \\in \\mathbb{R}$ a parameter that we can tweak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def toHamiltonian(x):\n",
    "    H = 0.5*(x[:, :, 0] + x[:, :, 0].T)\n",
    "    return H\n",
    "\n",
    "def plot_hamiltonian(x):\n",
    "    L = [x, toHamiltonian(x)]\n",
    "    labels = ['Matrix', 'Hamiltonian']\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(5, 5))\n",
    "    for i in range(2):\n",
    "        axes[i].imshow(L[i], cmap='gray_r')\n",
    "        axes[i].set_title(labels[i])\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the first image and its Hamiltonian\n",
    "plot_hamiltonian(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an example, we are computing the operator associated with the second image\n",
    "\n",
    "def U(x: np.ndarray, t: float) -> np.ndarray:\n",
    "    \"\"\"Compute the unitary operator associated with the Hamiltonian x and time t\"\"\"\n",
    "    H = toHamiltonian(x)\n",
    "    return linalg.expm(-1j*H*t)\n",
    "\n",
    "# M = pcvl.Matrix(U(X_train[1], 1000))\n",
    "# c1 = comp.Unitary(U=M)\n",
    "\n",
    "# Decompose the unitary into a circuit\n",
    "# ub = pcvl.Circuit(2, name=\"ub\") // comp.BS() // (0, comp.PS(phi=pcvl.Parameter(\"φ_a\"))) // comp.BS() // (1, comp.PS(phi=pcvl.Parameter(\"φ_b\")))\n",
    "# c2 = pcvl.Circuit.decomposition(M, ub, shape=pcvl.InterferometerShape.TRIANGLE)\n",
    "# pcvl.pdisplay(c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce the local effect of the convolution, the next layer will be constituted of a brickwork layout of 2 modes circuits that are acting on modes close to each other.\\\n",
    "\\\n",
    "The operator associated with this layer will be denoted $V(\\mathbf{\\omega})$, with $\\mathbf{\\omega}$ being the array of parameters of the 2 modes circuits.\\\n",
    "\\\n",
    "In some papers, we can read that this can be done with SU(N) gates. This is a more optimized approach that could be interesting to try in future upgrades, mainly, we have explicit formulas for the gradient of SU(N) gates that could improve the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"385.0\" height=\"468.75\" viewBox=\"-29.0 0 308.0 375.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L125,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,75 L125,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M27.5,2.5 L122.5,2.5 L122.5,97.5 L27.5,97.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"35\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">U2</text>\n",
       "<path d=\"M25,125 L125,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,175 L125,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M27.5,102.5 L122.5,102.5 L122.5,197.5 L27.5,197.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"35\" y=\"116\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">U2</text>\n",
       "<path d=\"M25,225 L125,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M25,275 L125,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M27.5,202.5 L122.5,202.5 L122.5,297.5 L27.5,297.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"35\" y=\"216\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">U2</text>\n",
       "<path d=\"M125,75 L225,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M125,125 L225,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M127.5,52.5 L222.5,52.5 L222.5,147.5 L127.5,147.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"135\" y=\"66\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">U2</text>\n",
       "<path d=\"M125,175 L225,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M125,225 L225,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M127.5,152.5 L222.5,152.5 L222.5,247.5 L127.5,247.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"135\" y=\"166\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">U2</text>\n",
       "<path d=\"M25,325.0 L125,325.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M125,275 L225,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M125,325 L225,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M127.5,252.5 L222.5,252.5 L222.5,347.5 L127.5,347.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"135\" y=\"266\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">U2</text>\n",
       "<path d=\"M125,25.0 L225,25.0\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M225,25.0 L240,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M225,75.0 L240,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M225,125.0 L240,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M225,175.0 L240,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M225,225.0 L240,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M225,275.0 L240,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M225,325.0 L240,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"250\" y=\"28.0\" font-size=\"8\" text-anchor=\"end\">0</text>\n",
       "<text x=\"250\" y=\"78.0\" font-size=\"8\" text-anchor=\"end\">1</text>\n",
       "<text x=\"250\" y=\"128.0\" font-size=\"8\" text-anchor=\"end\">2</text>\n",
       "<text x=\"250\" y=\"178.0\" font-size=\"8\" text-anchor=\"end\">3</text>\n",
       "<text x=\"250\" y=\"228.0\" font-size=\"8\" text-anchor=\"end\">4</text>\n",
       "<text x=\"250\" y=\"278.0\" font-size=\"8\" text-anchor=\"end\">5</text>\n",
       "<text x=\"250\" y=\"328.0\" font-size=\"8\" text-anchor=\"end\">6</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"8\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"8\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"8\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"8\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"8\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"8\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"8\" text-anchor=\"start\">6</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7fbb0b97e430>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def brickwork(\n",
    "    omega: np.ndarray,\n",
    "    num_modes: int,\n",
    ") -> Circuit:\n",
    "    \"\"\"\n",
    "    Create a brickwork circuit with generic 2 modes circuits.\n",
    "    Args:   \n",
    "        omega         : generic 2 modes circuits parameters (shape: [num_modes - 1, 4])\n",
    "        num_modes : Width of circuit\n",
    "    Returns:\n",
    "        Circuit\n",
    "    \"\"\"\n",
    "    circ = Circuit(num_modes)\n",
    "    even_modes = np.arange(0, num_modes - 1, 2)\n",
    "    odd_modes = np.arange(1, num_modes - 1, 2)\n",
    "\n",
    "    for k in even_modes:\n",
    "        params = omega[int(k)]\n",
    "        circ.add(int(k), catalog[\"generic 2 mode circuit\"].build_circuit(theta=params[0], phi_tl=params[1], phi_bl=params[2], phi_tr=params[3]))\n",
    "    for j in odd_modes:\n",
    "        params = omega[int(j)]\n",
    "        circ.add(int(j), catalog[\"generic 2 mode circuit\"].build_circuit(theta=params[0], phi_tl=params[1], phi_bl=params[2], phi_tr=params[3]))\n",
    "\n",
    "    return circ\n",
    "\n",
    "# Example of a V(omega) layer\n",
    "omega = np.zeros((6, 4))\n",
    "c2 = brickwork(omega, 7)\n",
    "pcvl.pdisplay(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1,1,1,1,1,1,1>\n",
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "N = 7      # Number of photons\n",
    "m = 7      # Number of modes   \n",
    "L = 5       # Number of layers\n",
    "\n",
    "# Input state with N photons and m modes\n",
    "input_state = pcvl.BasicState([1]*N+[0]*(m-N))\n",
    "print(input_state)\n",
    "\n",
    "# Random parameters for the circuit initialization\n",
    "t_params = np.random.uniform(0, 100, L)\n",
    "omega_params = np.random.uniform(0, 2*np.pi, (L*(m-1), 4))\n",
    "print(omega_params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code will follow the following scheme:\n",
    "- Use the fonction **create_circuit(x, params)** that create the circuit with L layers $U_t(\\mathbf{x}) V(\\mathbf{\\omega})$ associated to the image $\\mathbf{x}$.\n",
    "- Compute the full output probability with the input $N*|1>$.\n",
    "- Convert the output into a predicted label\n",
    "- Compute the sparse categorical cross-entropy loss (that is a function of $\\mathbf{x}$ and the parameters)\n",
    "- Do a minimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
       "     width=\"2947.5\" height=\"468.75\" viewBox=\"-29.0 0 2358.0 375.0\">\n",
       "<defs>\n",
       "</defs>\n",
       "<path d=\"M10,25.0 L25,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,75.0 L25,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,125.0 L25,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,175.0 L25,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,225.0 L25,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,275.0 L25,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M10,325.0 L25,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,25 L375,25\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,75 L375,75\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,125 L375,125\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,175 L375,175\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,225 L375,225\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,275 L375,275\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M25,325 L375,325\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M30,5 L370,5 L370,345 L30,345 Z\" stroke=\"black\" fill=\"gold\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"200\" y=\"175\" font-size=\"10\" text-anchor=\"middle\">Unitary</text>\n",
       "<path d=\"M375,25 L475,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M375,75 L475,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M375,125 L475,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M375,175 L475,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M375,225 L475,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M375,275 L475,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M375,325 L475,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M377.5,2.5 L472.5,2.5 L472.5,347.5 L377.5,347.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"385\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n",
       "<path d=\"M475,25 L825,25\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M475,75 L825,75\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M475,125 L825,125\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M475,175 L825,175\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M475,225 L825,225\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M475,275 L825,275\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M475,325 L825,325\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M480,5 L820,5 L820,345 L480,345 Z\" stroke=\"black\" fill=\"gold\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"650\" y=\"175\" font-size=\"10\" text-anchor=\"middle\">Unitary</text>\n",
       "<path d=\"M825,25 L925,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,75 L925,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,125 L925,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,175 L925,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,225 L925,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,275 L925,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M825,325 L925,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M827.5,2.5 L922.5,2.5 L922.5,347.5 L827.5,347.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"835\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n",
       "<path d=\"M925,25 L1275,25\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,75 L1275,75\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,125 L1275,125\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,175 L1275,175\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,225 L1275,225\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,275 L1275,275\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M925,325 L1275,325\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M930,5 L1270,5 L1270,345 L930,345 Z\" stroke=\"black\" fill=\"gold\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1100\" y=\"175\" font-size=\"10\" text-anchor=\"middle\">Unitary</text>\n",
       "<path d=\"M1275,25 L1375,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,75 L1375,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,125 L1375,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,175 L1375,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,225 L1375,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,275 L1375,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1275,325 L1375,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1277.5,2.5 L1372.5,2.5 L1372.5,347.5 L1277.5,347.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1285\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n",
       "<path d=\"M1375,25 L1725,25\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,75 L1725,75\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,125 L1725,125\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,175 L1725,175\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,225 L1725,225\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,275 L1725,275\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1375,325 L1725,325\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1380,5 L1720,5 L1720,345 L1380,345 Z\" stroke=\"black\" fill=\"gold\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1550\" y=\"175\" font-size=\"10\" text-anchor=\"middle\">Unitary</text>\n",
       "<path d=\"M1725,25 L1825,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,75 L1825,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,125 L1825,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,175 L1825,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,225 L1825,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,275 L1825,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1725,325 L1825,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M1727.5,2.5 L1822.5,2.5 L1822.5,347.5 L1727.5,347.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"1735\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n",
       "<path d=\"M1825,25 L2175,25\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,75 L2175,75\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,125 L2175,125\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,175 L2175,175\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,225 L2175,225\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,275 L2175,275\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1825,325 L2175,325\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M1830,5 L2170,5 L2170,345 L1830,345 Z\" stroke=\"black\" fill=\"gold\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2000\" y=\"175\" font-size=\"10\" text-anchor=\"middle\">Unitary</text>\n",
       "<path d=\"M2175,25 L2275,25\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2175,75 L2275,75\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2175,125 L2275,125\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2175,175 L2275,175\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2175,225 L2275,225\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2175,275 L2275,275\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2175,325 L2275,325\" stroke=\"darkred\" stroke-width=\"3\" fill=\"none\" />\n",
       "<path d=\"M2177.5,2.5 L2272.5,2.5 L2272.5,347.5 L2177.5,347.5 Z\" stroke=\"darkred\" fill=\"lightpink\" stroke-linejoin=\"miter\" />\n",
       "<text x=\"2185\" y=\"16\" font-size=\"8\" text-anchor=\"start\" font-weight=\"bold\">CPLX</text>\n",
       "<path d=\"M2275,25.0 L2290,25.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2275,75.0 L2290,75.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2275,125.0 L2290,125.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2275,175.0 L2290,175.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2275,225.0 L2290,225.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2275,275.0 L2290,275.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<path d=\"M2275,325.0 L2290,325.0\" stroke-width=\"3\" stroke=\"darkred\" stroke-linejoin=\"miter\" fill=\"none\" />\n",
       "<text x=\"2300\" y=\"28.0\" font-size=\"8\" text-anchor=\"end\">0</text>\n",
       "<text x=\"2300\" y=\"78.0\" font-size=\"8\" text-anchor=\"end\">1</text>\n",
       "<text x=\"2300\" y=\"128.0\" font-size=\"8\" text-anchor=\"end\">2</text>\n",
       "<text x=\"2300\" y=\"178.0\" font-size=\"8\" text-anchor=\"end\">3</text>\n",
       "<text x=\"2300\" y=\"228.0\" font-size=\"8\" text-anchor=\"end\">4</text>\n",
       "<text x=\"2300\" y=\"278.0\" font-size=\"8\" text-anchor=\"end\">5</text>\n",
       "<text x=\"2300\" y=\"328.0\" font-size=\"8\" text-anchor=\"end\">6</text>\n",
       "<text x=\"0\" y=\"28.0\" font-size=\"8\" text-anchor=\"start\">0</text>\n",
       "<text x=\"0\" y=\"78.0\" font-size=\"8\" text-anchor=\"start\">1</text>\n",
       "<text x=\"0\" y=\"128.0\" font-size=\"8\" text-anchor=\"start\">2</text>\n",
       "<text x=\"0\" y=\"178.0\" font-size=\"8\" text-anchor=\"start\">3</text>\n",
       "<text x=\"0\" y=\"228.0\" font-size=\"8\" text-anchor=\"start\">4</text>\n",
       "<text x=\"0\" y=\"278.0\" font-size=\"8\" text-anchor=\"start\">5</text>\n",
       "<text x=\"0\" y=\"328.0\" font-size=\"8\" text-anchor=\"start\">6</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<drawsvg.drawing.Drawing at 0x7fbb1fe9c6a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_circuit(x, t_params, omega_params):\n",
    "    c = Circuit(m)\n",
    "    for i in range(L):\n",
    "        c.add(0, comp.Unitary(U=pcvl.Matrix(U(x, t_params[i]))))\n",
    "        c.add(0, brickwork(omega_params[i*(m-1):(i+1)*(m-1)], m))\n",
    "    return c\n",
    "\n",
    "c = create_circuit(X_train[1], t_params, omega_params)\n",
    "pcvl.pdisplay(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probabilities(x, t_params, omega_params):\n",
    "    processor = pcvl.Processor(\"SLOS\", create_circuit(x, t_params, omega_params))\n",
    "    processor.with_input(input_state)\n",
    "    sampler = pcvl.algorithm.Sampler(processor)\n",
    "    prob_dist = sampler.probs()\n",
    "    return prob_dist\n",
    "\n",
    "# processor = pcvl.Processor(\"SLOS\", create_circuit(X_train[2], t_params, omega_params))\n",
    "# processor.with_input(input_state)\n",
    "\n",
    "# sampler = pcvl.algorithm.Sampler(processor)\n",
    "# prob_dist = sampler.probs()\n",
    "\n",
    "# argmax = np.argmax(list(prob_dist['results'].values()))\n",
    "# most_probable_output = list(prob_dist['results'].keys())[argmax]\n",
    "# most_probable_probability = list(prob_dist['results'].values())[argmax]\n",
    "\n",
    "# print(\"The most probable output is\", most_probable_output, \"with probability\", most_probable_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the output state of the circuit into a predicted label, my intuition is to think of the output state as a spatial distribution of guesses:\n",
    "* The more there are photons close to the top mode, the more the predicted label is close to 0\n",
    "* The more there are photons close to the bottom mode, the more the predicted label is close to 9\n",
    "\n",
    "I have decided to take the exponential of this spatial distribution, so that the output is less biased towards middle values like 4 or 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from the repartition of photon in the most probable output to a label\n",
    "def output_to_label(output):\n",
    "    return int(np.round(np.average(range(len(output)), weights=np.exp(output))*3/2))       # Scale the output to the range [0, 9]\n",
    "\n",
    "def confidence_array(prob_dist):\n",
    "    confidence = np.zeros(NUM_CLASSES)\n",
    "    for output, prob in prob_dist['results'].items():\n",
    "        label = output_to_label(output)\n",
    "        confidence[label] += prob\n",
    "    return confidence\n",
    "\n",
    "# print(output_to_label(most_probable_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    return -np.log(y_pred[y_true])\n",
    "\n",
    "def sparse_categorical_accuracy(y_true, y_pred):\n",
    "    return np.argmax(y_pred) == y_true\n",
    "\n",
    "def model_accuracy(X, y, t_params, omega_params):\n",
    "    accuracy = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        prob_dist = compute_probabilities(X[i], t_params, omega_params)\n",
    "        confidence = confidence_array(prob_dist)\n",
    "        y_pred = np.argmax(confidence)\n",
    "        y_true = np.argmax(y[i])\n",
    "        accuracy += sparse_categorical_accuracy(y_true, confidence)\n",
    "    return accuracy/X.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m batch_x \u001b[38;5;241m=\u001b[39m X_train[\u001b[38;5;241m0\u001b[39m: BATCH_SIZE]\n\u001b[1;32m     55\u001b[0m batch_y \u001b[38;5;241m=\u001b[39m y_train[\u001b[38;5;241m0\u001b[39m: BATCH_SIZE]\n\u001b[0;32m---> 56\u001b[0m t_params, omega_params, loss \u001b[38;5;241m=\u001b[39m \u001b[43mminimize_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momega_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdated t_params:\u001b[39m\u001b[38;5;124m\"\u001b[39m, t_params)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdated omega_params:\u001b[39m\u001b[38;5;124m\"\u001b[39m, omega_params)\n",
      "Cell \u001b[0;32mIn[12], line 33\u001b[0m, in \u001b[0;36mminimize_step\u001b[0;34m(batch_x, batch_y, t_params, omega_params, learning_rate_o, learning_rate_t)\u001b[0m\n\u001b[1;32m     31\u001b[0m omega_params[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m epsilon\n\u001b[1;32m     32\u001b[0m prob_dist \u001b[38;5;241m=\u001b[39m compute_probabilities(x, t_params, omega_params)\n\u001b[0;32m---> 33\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mconfidence_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob_dist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m loss_plus \u001b[38;5;241m=\u001b[39m sparse_categorical_crossentropy(np\u001b[38;5;241m.\u001b[39margmax(y_true), y_pred)\n\u001b[1;32m     36\u001b[0m grad_omega_params[i] \u001b[38;5;241m=\u001b[39m (loss_plus \u001b[38;5;241m-\u001b[39m loss) \u001b[38;5;241m/\u001b[39m epsilon\n",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m, in \u001b[0;36mconfidence_array\u001b[0;34m(prob_dist)\u001b[0m\n\u001b[1;32m      6\u001b[0m confidence \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(NUM_CLASSES)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output, prob \u001b[38;5;129;01min\u001b[39;00m prob_dist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 8\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[43moutput_to_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     confidence[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prob\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m confidence\n",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m, in \u001b[0;36moutput_to_label\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moutput_to_label\u001b[39m(output):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(np\u001b[38;5;241m.\u001b[39maverage(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(output)), weights\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def minimize_step(batch_x, batch_y, t_params, omega_params, learning_rate_o=0.03, learning_rate_t=0.1):\n",
    "    avg_gradient_t = np.zeros_like(t_params)\n",
    "    avg_gradient_o = np.zeros_like(omega_params)\n",
    "    avg_loss = 0\n",
    "\n",
    "    for x, y_true in zip(batch_x, batch_y):\n",
    "\n",
    "        # Compute the probabilities\n",
    "        prob_dist = compute_probabilities(x, t_params, omega_params)\n",
    "        y_pred = confidence_array(prob_dist)\n",
    "    \n",
    "        # Compute the loss\n",
    "        loss = sparse_categorical_crossentropy(np.argmax(y_true), y_pred)\n",
    "        avg_loss += loss\n",
    "    \n",
    "        # Compute the gradients (numerical gradient approximation)\n",
    "        grad_t_params = np.zeros_like(t_params)\n",
    "        grad_omega_params = np.zeros_like(omega_params)\n",
    "    \n",
    "        epsilon = 0.01\n",
    "        for i in range(len(t_params)):\n",
    "            t_params[i] += epsilon\n",
    "            prob_dist = compute_probabilities(x, t_params, omega_params)\n",
    "            y_pred = confidence_array(prob_dist)\n",
    "            loss_plus = sparse_categorical_crossentropy(np.argmax(y_true), y_pred)\n",
    "        \n",
    "            grad_t_params[i] = (loss_plus - loss) / epsilon\n",
    "            t_params[i] -= epsilon\n",
    "    \n",
    "        for i in range(len(omega_params)):\n",
    "            omega_params[i] += epsilon\n",
    "            prob_dist = compute_probabilities(x, t_params, omega_params)\n",
    "            y_pred = confidence_array(prob_dist)\n",
    "            loss_plus = sparse_categorical_crossentropy(np.argmax(y_true), y_pred)\n",
    "        \n",
    "            grad_omega_params[i] = (loss_plus - loss) / epsilon\n",
    "            omega_params[i] -= epsilon\n",
    "    \n",
    "        avg_gradient_t += grad_t_params\n",
    "        avg_gradient_o += grad_omega_params\n",
    "\n",
    "    avg_loss /= len(batch_x)\n",
    "    avg_gradient_t /= len(batch_x)\n",
    "    avg_gradient_o /= len(batch_x)\n",
    "\n",
    "    # Update the parameters\n",
    "    t_params -= learning_rate_t * avg_gradient_t\n",
    "    omega_params -= learning_rate_o * avg_gradient_o\n",
    "    # print(np.max(grad_t_params), np.max(grad_omega_params))\n",
    "    \n",
    "    return t_params, omega_params, avg_loss\n",
    "\n",
    "# Example usage\n",
    "batch_x = X_train[0: BATCH_SIZE]\n",
    "batch_y = y_train[0: BATCH_SIZE]\n",
    "t_params, omega_params, loss = minimize_step(batch_x, batch_y, t_params, omega_params)\n",
    "print(\"Updated t_params:\", t_params)\n",
    "print(\"Updated omega_params:\", omega_params)\n",
    "print(\"Batch loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/94 [03:53<6:02:27, 233.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.632051876633024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 2/94 [07:49<6:00:15, 234.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6742644019628634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 3/94 [11:45<5:56:54, 235.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6506725528230533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 4/94 [15:40<5:53:08, 235.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6871506572420065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 5/94 [19:37<5:49:35, 235.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6648098684809134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 6/94 [23:32<5:45:42, 235.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.916231436185227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 7/94 [27:40<5:47:18, 239.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.797246775863258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 8/94 [31:36<5:41:54, 238.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.600902094658121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 9/94 [35:29<5:35:32, 236.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5298831950242553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 10/94 [39:29<5:33:01, 237.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5333925233489962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 11/94 [43:21<5:26:28, 236.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7953316996887323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 12/94 [47:24<5:25:14, 237.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.8462777011761635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 13/94 [51:30<5:24:36, 240.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.449176736265692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 14/94 [55:59<5:32:03, 249.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.423853621694894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 15/94 [1:00:14<5:30:30, 251.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5929939229493457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 16/94 [1:04:08<5:19:40, 245.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.625094310171455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 17/94 [1:08:00<5:10:12, 241.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.635295779530891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 18/94 [1:11:52<5:02:19, 238.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.565975088393935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 19/94 [1:15:44<4:55:46, 236.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.744309563283925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 20/94 [1:19:35<4:50:00, 235.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.84534052367436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 21/94 [1:23:27<4:44:47, 234.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5294047201733076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 22/94 [1:27:20<4:40:24, 233.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.669247110094025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 23/94 [1:31:34<4:43:56, 239.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7612908757162535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 24/94 [1:35:21<4:35:06, 235.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.763971304709317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 25/94 [1:39:08<4:28:16, 233.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6189962830540625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 26/94 [1:42:55<4:22:24, 231.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6820200974489588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▊       | 27/94 [1:46:43<4:17:14, 230.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5406069630360273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|██▉       | 28/94 [1:50:30<4:12:15, 229.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7874349931053084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|███       | 29/94 [1:54:17<4:07:46, 228.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.495371459978209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 30/94 [1:58:05<4:03:30, 228.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.67421972243449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 31/94 [2:01:52<3:59:29, 228.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.668715908759765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  34%|███▍      | 32/94 [2:05:40<3:55:33, 227.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7282098327779054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 33/94 [2:09:27<3:51:29, 227.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.559604057418414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  36%|███▌      | 34/94 [2:13:14<3:47:30, 227.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6759582294185784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|███▋      | 35/94 [2:17:02<3:43:44, 227.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5020620199342987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 36/94 [2:20:49<3:40:01, 227.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7237663079563768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███▉      | 37/94 [2:24:37<3:36:07, 227.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7951191240284743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 38/94 [2:28:24<3:32:13, 227.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7110741323424703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|████▏     | 39/94 [2:32:10<3:28:16, 227.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7386280091018813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 40/94 [2:35:57<3:24:23, 227.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6029305342439013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  44%|████▎     | 41/94 [2:39:45<3:20:38, 227.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.74579022384937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▍     | 42/94 [2:43:32<3:16:52, 227.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.660585187584163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  46%|████▌     | 43/94 [2:47:20<3:13:14, 227.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.509370233980635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 44/94 [2:51:06<3:09:19, 227.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.624282269456398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 45/94 [2:54:53<3:05:27, 227.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6808480573432285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  49%|████▉     | 46/94 [2:58:40<3:01:41, 227.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4970621657256857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 47/94 [3:02:28<2:57:57, 227.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.666701898337686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  51%|█████     | 48/94 [3:06:15<2:54:12, 227.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.739100765985712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 49/94 [3:10:03<2:50:30, 227.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5789710597756677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|█████▎    | 50/94 [3:13:50<2:46:43, 227.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6431997314358084\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "def train(X_train, y_train, X_val, y_val, t_params, omega_params, learning_rate_t=0.1, learning_rate_o=0.03, epochs=1):\n",
    "    loss_history = []\n",
    "    val_acc_history = []\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch\", epoch)\n",
    "        shuffled_indices = np.random.permutation(len(X_train))\n",
    "        for batch in tqdm(range(0, len(X_train), BATCH_SIZE), desc=\"Training\"):\n",
    "            batch_indices = shuffled_indices[batch: min(batch + BATCH_SIZE, len(X_train))]\n",
    "            x = X_train[batch_indices]\n",
    "            y_true = y_train[batch_indices]\n",
    "            t_params, omega_params, loss = minimize_step(x, y_true, t_params, omega_params, learning_rate_t, learning_rate_o)\n",
    "            print(\"Loss:\", loss)\n",
    "            loss_history.append(loss)\n",
    "        val_acc = model_accuracy(X_val, y_val, t_params, omega_params)\n",
    "        val_acc_history.append(val_acc)\n",
    "        print(\"Validation accuracy:\", val_acc)\n",
    "    return t_params, omega_params, loss_history, val_acc_history\n",
    "\n",
    "t_params, omega_params, loss_history, val_acc_history = train(X_train, y_train, X_val, y_val, t_params, omega_params, epochs=1)\n",
    "# In my case, using 10 cores, the training takes about 6 hour for one epoch\n",
    "\n",
    "# Save the parameters\n",
    "\n",
    "# Ensure the directory exists\n",
    "modelparams_dir = os.path.join(script_dir, 'modelparams')\n",
    "os.makedirs(modelparams_dir, exist_ok=True)\n",
    "\n",
    "# Save the parameters\n",
    "np.save(os.path.join(modelparams_dir, 't_params.npy'), t_params)\n",
    "np.save(os.path.join(modelparams_dir, 'omega_params.npy'), omega_params)\n",
    "np.save(os.path.join(modelparams_dir, 'loss_history.npy'), loss_history)\n",
    "np.save(os.path.join(modelparams_dir, 'val_acc_history.npy'), val_acc_history)\n",
    "\n",
    "# Plot the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Number of batches\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss history\")\n",
    "plt.grid()\n",
    "\n",
    "plt.savefig(os.path.join(modelparams_dir, \"loss_history.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelparams_dir = os.path.join(script_dir, 'modelparams')\n",
    "os.makedirs(modelparams_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validarion accuracy: 0.10666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Load the parameters\n",
    "\n",
    "t_params = np.load(os.path.join(modelparams_dir, 't_params.npy'))\n",
    "omega_params = np.load(os.path.join(modelparams_dir, 'omega_params.npy'))\n",
    "loss_history = np.load(os.path.join(modelparams_dir, 'loss_history.npy'))\n",
    "val_acc_history = np.load(os.path.join(modelparams_dir, 'val_acc_history.npy'))\n",
    "\n",
    "print(\"Validarion accuracy:\", val_acc_history[-1])\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "# print(\"Training accuracy:\", model_accuracy(X_train, y_train, t_params, omega_params))\n",
    "# print(\"Validation accuracy:\", model_accuracy(X_val, y_val, t_params, omega_params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
